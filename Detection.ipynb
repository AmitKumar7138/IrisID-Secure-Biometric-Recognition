{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4102f5b-4a96-4c01-96b1-16153f78fda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: roboflow in /home/kumar.amit1/.local/lib/python3.8/site-packages (1.0.5)\n",
      "Requirement already satisfied: python-dateutil in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /apps/yolo/v8/lib/python3.8/site-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in /apps/yolo/v8/lib/python3.8/site-packages (from roboflow) (4.7.0.68)\n",
      "Requirement already satisfied: chardet==4.0.0 in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: matplotlib in /apps/yolo/v8/lib/python3.8/site-packages (from roboflow) (3.6.3)\n",
      "Requirement already satisfied: python-dotenv in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: requests-toolbelt in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (0.10.1)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: six in /apps/yolo/v8/lib/python3.8/site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /apps/yolo/v8/lib/python3.8/site-packages (from roboflow) (1.26.11)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /apps/yolo/v8/lib/python3.8/site-packages (from roboflow) (1.22.3)\n",
      "Requirement already satisfied: wget in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (3.2)\n",
      "Requirement already satisfied: idna==2.10 in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (9.5.0)\n",
      "Requirement already satisfied: certifi==2022.12.7 in /apps/yolo/v8/lib/python3.8/site-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /apps/yolo/v8/lib/python3.8/site-packages (from roboflow) (4.64.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /apps/yolo/v8/lib/python3.8/site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: requests in /home/kumar.amit1/.local/lib/python3.8/site-packages (from roboflow) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/yolo/v8/lib/python3.8/site-packages (from matplotlib->roboflow) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /apps/yolo/v8/lib/python3.8/site-packages (from matplotlib->roboflow) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /apps/yolo/v8/lib/python3.8/site-packages (from matplotlib->roboflow) (4.38.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kumar.amit1/.local/lib/python3.8/site-packages (from requests->roboflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fd45ab-2d4c-460e-a14e-178ae56d653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085043da-367d-4288-bc9e-961a64616fd1",
   "metadata": {},
   "source": [
    "# download the dataset from roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38adb176-5841-449f-a00d-da8d0eac8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset from roboflow\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"QTj9X7XTgxhw26sGOhJp\")\n",
    "project = rf.workspace(\"myworkspace-l4whl\").project(\"iris_detection-iozew\")\n",
    "dataset = project.version(2).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae78b7-38ec-48ec-8458-6dd41922d8b7",
   "metadata": {},
   "source": [
    "# Trainin the yolov8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6a5997-86de-4611-838b-55a3981cfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainin the yolov8 model\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained YOLOv8n model\n",
    " \n",
    "model.train(data=\"Iris_detection-2/data.yaml\")  # train the model\n",
    "model.val()  # evaluate model performance on the validation set\n",
    "#model.predict(source=\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "#model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa79906-40ca-42e9-83ef-cc089c9fb295",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f03246-2a42-4197-8508-f76894490235",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da04225-c3d4-4233-baf1-77a667879bdb",
   "metadata": {},
   "source": [
    "# Function for prediction task outputs the predciction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3103a80-449e-43cc-8099-5559e81fc1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_img(img_path):\n",
    "    model_trained = YOLO(\"runs/detect/train9/weights/best.pt\")\n",
    "    results = model_trained.predict(img_path,save=True)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows() \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2809a-8e0e-4012-ab02-85a2ef29be30",
   "metadata": {},
   "source": [
    "### The predcited image is saved in the following path \" runs/detect/predict/image.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bf76793-321c-4801-abb8-829c6c9217da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.25 ðŸš€ Python-3.8.13 torch-1.13.1 CUDA:0 (NVIDIA A100-SXM4-80GB, 81251MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/1 /home/kumar.amit1/ondemand/data/sys/myjobs/projects/default/1/data/data/anchor/RE110.jpg: 640x640 1 Iris, 7.0ms\n",
      "Speed: 2.1ms pre-process, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
       " type: <class 'torch.Tensor'>\n",
       " shape: torch.Size([1, 6])\n",
       " dtype: torch.float32\n",
       "  + tensor([[248.00000, 398.00000, 671.00000, 741.00000,   0.90128,   0.00000]], device='cuda:0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_img('data/anchor/RE110.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f99bfa-17e1-43e6-b36f-9f494cebf059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = YOLO(\"runs/detect/train9/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725e684-be52-4e70-b7bf-363b55fc5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4cad7-624d-44de-9b70-08db4c8c32b1",
   "metadata": {},
   "source": [
    "# Creating directiory for preparing data for iris recogniton task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6957bce-f8c2-419e-adf8-fd4e3e856ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Iris recogniton dataset \n",
    "root_folder = 'data'\n",
    "# Creates and saves path for recogntion task\n",
    "save_folder = 'data_crop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d89cd-e3cd-4a33-9ff4-5372260b6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd8dff-f97d-4e5b-85cb-8bd992fea068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subfolders to read images from\n",
    "subfolders = ['anchor', 'negative', 'positive']\n",
    "\n",
    "# # Create the directory structure\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(root_folder, subfolder)\n",
    "    print(subfolder_path)\n",
    "    save_subfolder = subfolder + '_crop'\n",
    "    save_subfolder_path = os.path.join(save_folder, save_subfolder)\n",
    "    os.makedirs(save_subfolder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe2ebf-024e-435d-a30e-2237e5f05645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(root_folder, save_folder):\n",
    "    # Define the subfolders to read images from\n",
    "    subfolders = ['anchor', 'negative', 'positive']\n",
    "\n",
    "    # Loop through each subfolder\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(root_folder, subfolder)\n",
    "        save_subfolder = subfolder + '_crop2'\n",
    "        save_subfolder_path = os.path.join(save_folder, save_subfolder)\n",
    "        os.makedirs(save_subfolder_path, exist_ok=True)\n",
    "\n",
    "        # Loop through each image in the subfolder\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            if filename.endswith('.jpg'):\n",
    "                image_path = os.path.join(subfolder_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Perform YOLOv8 prediction\n",
    "                results = model.predict(image_path)\n",
    "                for result in results:\n",
    "                    co = result.boxes.xywh\n",
    "\n",
    "                # Check if the output contains valid predictions\n",
    "                if len(co) > 0:\n",
    "                    x = int(co[0][0])\n",
    "                    y = int(co[0][1])\n",
    "                    width = int(co[0][2])\n",
    "                    height = int(co[0][3])\n",
    "\n",
    "                    # # Convert to integers\n",
    "                    # x = int(x)\n",
    "                    # y = int(y)\n",
    "                    # width = int(width)\n",
    "                    # height = int(height)\n",
    "\n",
    "                    # Calculate the top-left corner coordinates of the bounding box\n",
    "                    x_min = x - (width // 2)\n",
    "                    y_min = y - (height // 2)\n",
    "\n",
    "                    # Calculate the bottom-right corner coordinates of the bounding box\n",
    "                    x_max = x + (width // 2)\n",
    "                    y_max = y + (height // 2)\n",
    "\n",
    "                    # Crop the image using the bounding box coordinates\n",
    "                    cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "                    \n",
    "                    alpha = 1.5  \n",
    "                    # control brightness by 50\n",
    "                    beta = 50  \n",
    "                    image2 = cv2.convertScaleAbs(cropped_image, alpha=alpha, beta=beta)\n",
    "                    \n",
    "                    # Apply median blur\n",
    "                    ksize = 5  # kernel size, should be an odd number\n",
    "                    image_blur = cv2.medianBlur(image2, ksize)\n",
    "\n",
    "                    # Create the sharpening kernel\n",
    "                    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "\n",
    "                    # Sharpen the image\n",
    "                    sharpened_image = cv2.filter2D(image_blur, -1, kernel)\n",
    "\n",
    "                    #Save the image\n",
    "                    cv2.imwrite('sharpened_image.jpg', sharpened_image)\n",
    "\n",
    "                    # Get the save path for the cropped image\n",
    "                    save_path = os.path.join(save_subfolder_path, filename)\n",
    "\n",
    "                    # Save the cropped image to a file\n",
    "                    cv2.imwrite(save_path, cropped_image)\n",
    "                else:\n",
    "                    print(f\"No predictions found for {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe26fdd-6b4b-4291-ae6a-dba40924e5b5",
   "metadata": {},
   "source": [
    "# Saves the Enhanced and Cropped image in there respective directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4895182-5878-4c79-9c8a-cc4ce0516c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_image(root_folder, save_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolo-v8",
   "language": "python",
   "name": "yolo-v8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
